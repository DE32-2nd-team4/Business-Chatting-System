{
  "metadata": {
    "name": "toparquet",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "sc.version"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n# parquet 파일 읽기\ndf \u003d spark.read.parquet(\u0027\u003cyour installation folder\u003e/data/parquet/p.parquet\u0027)\nz.show(df)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\ndf.createOrReplaceTempView(\"chat\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n-- 닉네임 별 채팅 빈도\nSELECT nickname, COUNT(*) AS count\nFROM chat\nGROUP BY nickname;"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n# 날짜 형식 통일\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, udf\nfrom pyspark.sql.types import TimestampType\nimport datetime\nimport re\n\n# Spark 세션 생성\nspark \u003d SparkSession.builder.appName(\"DateConversion\").getOrCreate()\n\n# Unix 타임스탬프를 변환하는 함수\ndef unix_to_datetime(timestamp):\n    try:\n        return datetime.datetime.fromtimestamp(float(timestamp))\n    except ValueError:\n        return None\n\n# 날짜 형식을 인식하고 변환하는 함수\ndef parse_date(date_str):\n    formats \u003d [\n        \"%Y-%m-%d %H:%M:%S\",  # 형식: 2024-08-27 10:45:24\n        \"%a %b %d %H:%M:%S %Y\",  # 형식: Tue Aug 27 11:04:45 2024\n    ]\n    \n    # Unix 타임스탬프인지 확인\n    if re.match(r\u0027^\\d+(\\.\\d+)?$\u0027, date_str):\n        return unix_to_datetime(date_str)\n    \n    # 날짜 형식 시도\n    for fmt in formats:\n        try:\n            return datetime.datetime.strptime(date_str, fmt)\n        except ValueError:\n            continue\n    return None\n\n# UDF 등록\nparse_date_udf \u003d udf(parse_date, TimestampType())\n\n# 데이터프레임에 UDF 적용\ndf \u003d df.withColumn(\"parsed_time\", parse_date_udf(col(\"time\")))\nz.show(df)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\ndf.createOrReplaceTempView(\"chat_time\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n-- 날짜 별 채팅 빈도\nSELECT \n    to_date(parsed_time) AS date,\n    COUNT(*) AS count\nFROM \n    chat_time\nGROUP BY \n    to_date(parsed_time)\nORDER BY \n    date"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n-- 날짜 + 시간 별 채팅 빈도\nSELECT \n    date_format(parsed_time, \u0027yyyy-MM-dd HH:00:00\u0027) AS date_hour,\n    COUNT(*) AS count\nFROM \n    chat_time\nGROUP BY \n    date_format(parsed_time, \u0027yyyy-MM-dd HH:00:00\u0027)\nORDER BY \n    date_hour"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.pyspark\n# 단어 빈도 계산(상위 19개)\n\nfrom pyspark.sql.functions import col, explode, split, lower, regexp_replace, trim\n\n# 메시지가 빈 경우 필터링\ndf_filtered \u003d df.filter(col(\u0027message\u0027).isNotNull() \u0026 (trim(col(\u0027message\u0027)) !\u003d \u0027\u0027))\n\n# 메시지에서 특수문자 및 구두점 제거\ndf_cleaned \u003d df_filtered.withColumn(\n    \u0027clean_message\u0027,\n    regexp_replace(col(\u0027message\u0027), \u0027[^\\\\w\\\\s가-힣]\u0027, \u0027\u0027)  # 영문자, 숫자, 공백, 한글만 허용\n)\n\n# 메시지에서 단어 분리 및 소문자 변환\nwords_df \u003d df_cleaned.withColumn(\u0027word\u0027, explode(split(lower(col(\u0027clean_message\u0027)), \u0027\\\\s+\u0027)))\n\n# 빈 단어 제거 (단어가 공백이거나 NULL인 경우)\nwords_df_filtered \u003d words_df.filter(col(\u0027word\u0027) !\u003d \u0027\u0027)\n\n# 단어 빈도 계산\nword_count_df \u003d words_df_filtered.groupBy(\u0027word\u0027).count().orderBy(col(\u0027count\u0027).desc())\n\n# 결과 출력\n\ntop_10_words_df \u003d word_count_df.limit(10)\ntop_10_words_df.show(truncate\u003dFalse)\n\ntop_10_words_df.createOrReplaceTempView(\"frequent\")\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\n-- 단어 빈도 시각화\nselect * from frequent\n"
    }
  ]
}